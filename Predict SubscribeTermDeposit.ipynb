{"cells":[{"cell_type":"markdown","source":["### Predicting Customer Bank Term Deposit Subscription"],"metadata":{}},{"cell_type":"markdown","source":["#### The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. By building predictive models using machine learning algorithms, we can predict whether a clinet is subscribing to term deposit due to the campaign conducted.The classification goal is to predict if the client will subscribe a term deposit (variable y)"],"metadata":{}},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/bank_full-bd3df.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \";\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndf.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[1]: [Row(age=&#39;58&#39;, job=&#39;management&#39;, marital=&#39;married&#39;, education=&#39;tertiary&#39;, default=&#39;no&#39;, balance=&#39;2143&#39;, housing=&#39;yes&#39;, loan=&#39;no&#39;, contact=&#39;unknown&#39;, day=&#39;5&#39;, month=&#39;may&#39;, duration=&#39;261&#39;, campaign=&#39;1&#39;, pdays=&#39;-1&#39;, previous=&#39;0&#39;, poutcome=&#39;unknown&#39;, y=&#39;no&#39;),\n Row(age=&#39;44&#39;, job=&#39;technician&#39;, marital=&#39;single&#39;, education=&#39;secondary&#39;, default=&#39;no&#39;, balance=&#39;29&#39;, housing=&#39;yes&#39;, loan=&#39;no&#39;, contact=&#39;unknown&#39;, day=&#39;5&#39;, month=&#39;may&#39;, duration=&#39;151&#39;, campaign=&#39;1&#39;, pdays=&#39;-1&#39;, previous=&#39;0&#39;, poutcome=&#39;unknown&#39;, y=&#39;no&#39;),\n Row(age=&#39;33&#39;, job=&#39;entrepreneur&#39;, marital=&#39;married&#39;, education=&#39;secondary&#39;, default=&#39;no&#39;, balance=&#39;2&#39;, housing=&#39;yes&#39;, loan=&#39;yes&#39;, contact=&#39;unknown&#39;, day=&#39;5&#39;, month=&#39;may&#39;, duration=&#39;76&#39;, campaign=&#39;1&#39;, pdays=&#39;-1&#39;, previous=&#39;0&#39;, poutcome=&#39;unknown&#39;, y=&#39;no&#39;),\n Row(age=&#39;47&#39;, job=&#39;blue-collar&#39;, marital=&#39;married&#39;, education=&#39;unknown&#39;, default=&#39;no&#39;, balance=&#39;1506&#39;, housing=&#39;yes&#39;, loan=&#39;no&#39;, contact=&#39;unknown&#39;, day=&#39;5&#39;, month=&#39;may&#39;, duration=&#39;92&#39;, campaign=&#39;1&#39;, pdays=&#39;-1&#39;, previous=&#39;0&#39;, poutcome=&#39;unknown&#39;, y=&#39;no&#39;),\n Row(age=&#39;33&#39;, job=&#39;unknown&#39;, marital=&#39;single&#39;, education=&#39;unknown&#39;, default=&#39;no&#39;, balance=&#39;1&#39;, housing=&#39;no&#39;, loan=&#39;no&#39;, contact=&#39;unknown&#39;, day=&#39;5&#39;, month=&#39;may&#39;, duration=&#39;198&#39;, campaign=&#39;1&#39;, pdays=&#39;-1&#39;, previous=&#39;0&#39;, poutcome=&#39;unknown&#39;, y=&#39;no&#39;)]</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### About Data"],"metadata":{}},{"cell_type":"markdown","source":["#### We have used dataset from UCI Machine Learning Repository.The data is related with direct marketing campaigns of a Portuguese banking institution.Each data entry involves the information about the customer which has features such as: \ncategorical variables : 1.Job, 2.Marital, 3.Education, 4.Housing, 5.Loan, 6. Month, 7.Poutcome, 8.Contact and 9. y (dependent varaible)\nNumeric Data Types : 1.Age, 2.Balance, 3.Day, 4.campaign,5.pdays 6.previous.\n\nIn the dataset the number of rows which contain the data for a customer subscribing to a term deposit is around 12% of the total data\n\nFor the purpose of the project, the dependent variable is whether the customer will subscribe to term deposit or not."],"metadata":{}},{"cell_type":"markdown","source":["#### Data Pre-processing"],"metadata":{}},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- age: string (nullable = true)\n-- job: string (nullable = true)\n-- marital: string (nullable = true)\n-- education: string (nullable = true)\n-- default: string (nullable = true)\n-- balance: string (nullable = true)\n-- housing: string (nullable = true)\n-- loan: string (nullable = true)\n-- contact: string (nullable = true)\n-- day: string (nullable = true)\n-- month: string (nullable = true)\n-- duration: string (nullable = true)\n-- campaign: string (nullable = true)\n-- pdays: string (nullable = true)\n-- previous: string (nullable = true)\n-- poutcome: string (nullable = true)\n-- y: string (nullable = true)\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql.types import IntegerType, FloatType, StringType, DoubleType, TimestampType\nfrom pyspark.sql.functions import when,count,col\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["df = df.withColumn('age',df['age'].cast(IntegerType())).\\\n         withColumn('balance',df['balance'].cast(IntegerType())).\\\n         withColumn('day',df['day'].cast(IntegerType())).\\\n         withColumn('duration',df['duration'].cast(IntegerType())).\\\n         withColumn('campaign',df['campaign'].cast(IntegerType())).\\\n         withColumn('pdays',df['pdays'].cast(IntegerType())).\\\n         withColumn('previous',df['previous'].cast(IntegerType())).\\\n         withColumn('y',regexp_replace('y', 'no', '0')).\\\n         withColumn('y',regexp_replace('y', 'yes', '1'))\n\ndf = df.withColumn('y',df['y'].cast(IntegerType()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- age: integer (nullable = true)\n-- job: string (nullable = true)\n-- marital: string (nullable = true)\n-- education: string (nullable = true)\n-- default: string (nullable = true)\n-- balance: integer (nullable = true)\n-- housing: string (nullable = true)\n-- loan: string (nullable = true)\n-- contact: string (nullable = true)\n-- day: integer (nullable = true)\n-- month: string (nullable = true)\n-- duration: integer (nullable = true)\n-- campaign: integer (nullable = true)\n-- pdays: integer (nullable = true)\n-- previous: integer (nullable = true)\n-- poutcome: string (nullable = true)\n-- y: integer (nullable = true)\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["df.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\nage|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown|  0|\n 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown|  0|\n 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown|  0|\n 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown|  0|\n 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown|  0|\n+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# Checking for count of null values present in each column\ndf.select([count(when(col(i).isNull(),i)).alias(i) for i in df.columns]).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\nage|job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n  0|  0|      0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|  0|\n+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["df.createOrReplaceTempView(\"bank_data\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["### Analysis"],"metadata":{}},{"cell_type":"markdown","source":["#### Number of subscribed and non-subscribed customers for term deposits ."],"metadata":{}},{"cell_type":"code","source":["df.groupby(df.y).count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+\n  y|count|\n+---+-----+\n  1| 5289|\n  0|39922|\n+---+-----+\n\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["####Top 5 professions with term deposits subscribed"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect \n job , count(*) as number from bank_data where y=1 group by job order by number desc limit 5;"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>job</th><th>number</th></tr></thead><tbody><tr><td>management</td><td>1301</td></tr><tr><td>technician</td><td>840</td></tr><tr><td>blue-collar</td><td>708</td></tr><tr><td>admin.</td><td>631</td></tr><tr><td>retired</td><td>516</td></tr></tbody></table></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["#####Month with highest percentage of term deposits"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.window import Window\nfrom pyspark.sql import functions as F\n\n\ndf.groupby('month','y').count().withColumnRenamed(\"count\",\"NumberOfSubscriptions\").\\\nwithColumn(\"Percentage\",F.round(F.col(\"NumberOfSubscriptions\")*100/F.sum(\"NumberOfSubscriptions\").over(Window.partitionBy()),2)).sort([\"y\",\"Percentage\"],ascending=[False,False]).select(['month','Percentage']).show(1,False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----------+\nmonth|Percentage|\n+-----+----------+\nmay  |2.05      |\n+-----+----------+\nonly showing top 1 row\n\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["#### Top 5 age group's with highest number of term deposit subscriptions"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect\n  AgeGroup,\n  sum(case when y= 1 then 1 else 0 end) as SuccessfulCampaigns,\n  count(y) as TotalCampaigns\nfrom (\n    select \n     case when age <= 20 then '0-20'\n          when age > 20 and age <= 30  then '20-30'\n          when age > 30 and age <= 40  then '30-40'\n          when age > 40 and age <= 50  then '40-50'\n          when age > 50 and age <= 60  then '50-60'\n          when age > 60 and age <= 70  then '60-70'\n          when age > 70 and age <= 80  then '70-80'\n          when age > 80 and age <= 90  then '80-90'\n          when age > 90 and age <= 100  then '90-100'\n     end as AgeGroup,\n     y\n    from bank_data\n)\n group by AgeGroup\n order by SuccessfulCampaigns desc limit 5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>AgeGroup</th><th>SuccessfulCampaigns</th><th>TotalCampaigns</th></tr></thead><tbody><tr><td>30-40</td><td>1812</td><td>17687</td></tr><tr><td>20-30</td><td>1112</td><td>6933</td></tr><tr><td>40-50</td><td>1019</td><td>11239</td></tr><tr><td>50-60</td><td>811</td><td>8067</td></tr><tr><td>60-70</td><td>284</td><td>701</td></tr></tbody></table></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["#### Breakdown of campaign success by Marital status of the person in percentages"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect MaritalStatus ,\ncast(SuccessfulCampaigns*100/TotalCampaigns as decimal(4,2)) as CampaignSuccessPercentage\nfrom (\n    select\n      marital as MaritalStatus,\n      sum(case when y= 1 then 1 else 0 end) as SuccessfulCampaigns,\n      count(y) as TotalCampaigns\n    from bank_data\n      group by marital\n)\norder by CampaignSuccessPercentage desc\nlimit 5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>MaritalStatus</th><th>CampaignSuccessPercentage</th></tr></thead><tbody><tr><td>single</td><td>14.95</td></tr><tr><td>divorced</td><td>11.95</td></tr><tr><td>married</td><td>10.12</td></tr></tbody></table></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["#### success percentage of term deposit campaign for customers who already have either credit default history or housing or personal loan"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect cast(SuccessCount*100/TotalCount as decimal(4,2)) as SuccessPercentage\nfrom (\n\n  select\n    sum(case when (default = \"yes\" or housing = \"yes\" or loan = \"yes\") and y = 1 then 1 else 0 end) as SuccessCount,\n    sum(case when default = \"yes\" or housing = \"yes\" or loan = \"yes\" then 1 else 0 end) as TotalCount\n  from bank_data\n\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>SuccessPercentage</th></tr></thead><tbody><tr><td>7.69</td></tr></tbody></table></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["#### Top 5 job categories with highest campaign success percentage"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect JobCategory,\ncast(SuccessfulCampaigns*100/TotalCampaigns as decimal(4,2)) as CampaignSuccessPercentage\nfrom (\n    select\n      job as JobCategory,\n      sum(case when y= 1 then 1 else 0 end) as SuccessfulCampaigns,\n      count(y) as TotalCampaigns\n    from bank_data\n      group by job\n)\norder by CampaignSuccessPercentage desc\nlimit 5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>JobCategory</th><th>CampaignSuccessPercentage</th></tr></thead><tbody><tr><td>student</td><td>28.68</td></tr><tr><td>retired</td><td>22.79</td></tr><tr><td>unemployed</td><td>15.5</td></tr><tr><td>management</td><td>13.76</td></tr><tr><td>admin.</td><td>12.2</td></tr></tbody></table></div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["#### Campaign Success Percentage by Contact Communication Type"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect ContactType,\ncast(SuccessfulCampaigns*100/TotalCampaigns as decimal(4,2)) as SuccessPercentage\nfrom (\n    select\n      contact as ContactType,\n      sum(case when y= 1 then 1 else 0 end) as SuccessfulCampaigns,\n      count(y) as TotalCampaigns\n    from bank_data\n      group by contact\n)\norder by SuccessPercentage desc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ContactType</th><th>SuccessPercentage</th></tr></thead><tbody><tr><td>cellular</td><td>14.92</td></tr><tr><td>telephone</td><td>13.42</td></tr><tr><td>unknown</td><td>4.07</td></tr></tbody></table></div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["#### Top 5 job categories which needed highest number of contacts in this campaign for subscribing to term deposit on an average"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nselect JobCategory, \n  cast(TotalContactsMade/SuccessfulCampaigns as decimal(4,2)) as Average_Contacts_Made_Per_One_SuccessfulCampaign\nfrom(\n    select job as JobCategory,\n      sum(campaign) as TotalContactsMade,\n      sum(case when y= 1 then 1 else 0 end) as SuccessfulCampaigns\n    from bank_data\n    group by JobCategory\n)\norder by Average_Contacts_Made_Per_One_SuccessfulCampaign desc\nlimit 5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>JobCategory</th><th>Average_Contacts_Made_Per_One_SuccessfulCampaign</th></tr></thead><tbody><tr><td>blue-collar</td><td>38.72</td></tr><tr><td>entrepreneur</td><td>33.85</td></tr><tr><td>housemaid</td><td>32.09</td></tr><tr><td>services</td><td>30.6</td></tr><tr><td>unknown</td><td>28.03</td></tr></tbody></table></div>"]}}],"execution_count":32},{"cell_type":"code","source":["%sql\n\nselect Month,\n  cast(SuccessfulCampaigns*100/TotalCampaigns as decimal(4,2)) as SuccessPercentage,\n  SuccessfulCampaigns,\n  TotalCampaigns\nfrom (\n    select\n      Month,\n      sum(case when y= 1 then 1 else 0 end) as SuccessfulCampaigns,\n      count(y) as TotalCampaigns\n    from bank_data\n      group by Month\n)\norder by SuccessPercentage desc limit 5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Month</th><th>SuccessPercentage</th><th>SuccessfulCampaigns</th><th>TotalCampaigns</th></tr></thead><tbody><tr><td>mar</td><td>51.99</td><td>248</td><td>477</td></tr><tr><td>dec</td><td>46.73</td><td>100</td><td>214</td></tr><tr><td>sep</td><td>46.46</td><td>269</td><td>579</td></tr><tr><td>oct</td><td>43.77</td><td>323</td><td>738</td></tr><tr><td>apr</td><td>19.68</td><td>577</td><td>2932</td></tr></tbody></table></div>"]}}],"execution_count":33},{"cell_type":"code","source":["data=df.select(['age','job','marital','education','default','balance','housing','loan','contact','day','month',\n                                 'campaign','pdays','previous','poutcome','y'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["data=data.dropna()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["train_data,test_data=data.randomSplit([0.8,0.2])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["### Models"],"metadata":{}},{"cell_type":"markdown","source":["#### Linear SVC Model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC\nfrom pyspark.ml.feature import VectorAssembler,StringIndexer,StandardScaler\nfrom pyspark.ml import Pipeline"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["# Use StringIndexer to convert the categorical columns to hold numerical data\n# handleInvalid is set to 'keep' which means that when a new class name is encountered in test dataset, in that case the StringIndexer will fail to find the label, and an exception will be raised, in order to avoid that and create new labels when new class in encountered 'keep' value for handleInvalid param helps\n\njob_indexer = StringIndexer(inputCol='job',outputCol='job_index',handleInvalid='keep')\nmarital_indexer = StringIndexer(inputCol='marital',outputCol='marital_index',handleInvalid='keep')\neducation_indexer = StringIndexer(inputCol='education',outputCol='education_index',handleInvalid='keep')\ndefault_indexer = StringIndexer(inputCol='default',outputCol='default_index',handleInvalid='keep')\nhousing_indexer = StringIndexer(inputCol='housing',outputCol='housing_index',handleInvalid='keep')\nloan_indexer = StringIndexer(inputCol='loan',outputCol='loan_index',handleInvalid='keep')\ncontact_indexer = StringIndexer(inputCol='contact',outputCol='contact_index',handleInvalid='keep')\nmonth_indexer = StringIndexer(inputCol='month',outputCol='month_index',handleInvalid='keep')\npoutcome_indexer = StringIndexer(inputCol='poutcome',outputCol='poutcome_index',handleInvalid='keep')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":40},{"cell_type":"code","source":["linearsvc_assembler = VectorAssembler(inputCols=['age','job_index','marital_index','education_index',\n                                       'default_index','housing_index','loan_index','contact_index','month_index',\n                                       'day','campaign','pdays','previous','poutcome_index'],\n                            outputCol=\"unscaled_features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"code","source":["# Since SVM's do not perform well on the data that is not scaled, scaling the data for better performance of the Linear SVC Model\n\nscaler = StandardScaler(inputCol=\"unscaled_features\",outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["linear_svc_model = LinearSVC(labelCol='y')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["# creating pipeline for all the above actions to be performed\n\nlinear_svc_pipe = Pipeline(stages=[job_indexer,marital_indexer,education_indexer,default_indexer,\n                        housing_indexer,loan_indexer,contact_indexer,month_indexer,poutcome_indexer,\n                        linearsvc_assembler,scaler,linear_svc_model])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["fit_Linear_svc_model = linear_svc_pipe.fit(train_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["# Store the results in a dataframe\n\nresults_linear_svc = fit_Linear_svc_model.transform(test_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":46},{"cell_type":"code","source":["results_linear_svc.select(['y','prediction']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+\n  y|prediction|\n+---+----------+\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n+---+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":47},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import VectorAssembler,StringIndexer,OneHotEncoderEstimator\nfrom pyspark.ml import Pipeline"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":49},{"cell_type":"code","source":["# OneHotEncoderEstimator converts the indexed data into a vector which will be effectively handled by Logistic Regression model\n\ndata_encoder = OneHotEncoderEstimator(inputCols=['job_index','marital_index','education_index',\n                                                 'contact_index','month_index','poutcome_index','day'],\n                                      outputCols=['job_index_enc','marital_index_enc','education_index_enc',\n                                                 'contact_index_enc','month_index_enc','poutcome_index_enc','day_enc'],\n                                      handleInvalid='keep')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["logistic_assembler = VectorAssembler(inputCols=['age','balance','job_index_enc','marital_index_enc','education_index_enc',\n                                       'default_index','housing_index','loan_index','contact_index_enc','month_index_enc',\n                                       'day_enc','campaign','pdays','previous','poutcome_index_enc'],\n                            outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":51},{"cell_type":"code","source":["# Creating an object for the Logistic Regression model\n\nlogreg_model = LogisticRegression(labelCol='y')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["# Pipeline is used to pass the data through indexer and assembler simultaneously. Also, it helps to pre-rocess the test data\n# in the same way as that of the train data. It also \n\nlogreg_pipe = Pipeline(stages=[job_indexer,marital_indexer,education_indexer,default_indexer,\n                        housing_indexer,loan_indexer,contact_indexer,month_indexer,poutcome_indexer,\n                        data_encoder,logistic_assembler,logreg_model])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":53},{"cell_type":"code","source":["fit_logreg_model=logreg_pipe.fit(train_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["# Storing the results in a dataframe\n\nlogreg_results = fit_logreg_model.transform(test_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":55},{"cell_type":"code","source":["logreg_results.select(['y','prediction']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+\n  y|prediction|\n+---+----------+\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n+---+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":56},{"cell_type":"markdown","source":["### Decision Trees"],"metadata":{}},{"cell_type":"code","source":["# Import the required libraries\n\nfrom pyspark.ml.classification import DecisionTreeClassifier"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["# Vector assembler is used to create a vector of input features\n\ngeneric_assembler = VectorAssembler(inputCols=['age','job_index','marital_index','education_index',\n                                       'default_index','housing_index','loan_index','contact_index','month_index',\n                                       'day','campaign','pdays','previous','poutcome_index'],\n                            outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"code","source":["# Create an object for the Logistic Regression model\n# Use the parameter maxBins and assign a value that is equal to or more than the number of categories in any sigle feature\n\ndt_model = DecisionTreeClassifier(labelCol='y',maxBins=10000)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":60},{"cell_type":"code","source":["# Pipeline is used to pass the data through indexer and assembler simultaneously. Also, it helps to pre-rocess the test data\n# in the same way as that of the train data. It also \n\ndt_pipe = Pipeline(stages=[job_indexer,marital_indexer,education_indexer,default_indexer,\n                        housing_indexer,loan_indexer,contact_indexer,month_indexer,poutcome_indexer,\n                        generic_assembler,dt_model])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":61},{"cell_type":"code","source":["dt_fit_model = dt_pipe.fit(train_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":62},{"cell_type":"code","source":["# Store the results in a dataframe\n\ndt_results = dt_fit_model.transform(test_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63},{"cell_type":"markdown","source":["### Random Forest Classifier"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":65},{"cell_type":"code","source":["rf_model = RandomForestClassifier(labelCol=\"y\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":66},{"cell_type":"code","source":["# creating pipeline for Random Forest Classifier\n\nrf_pipe = Pipeline(stages=[job_indexer,marital_indexer,education_indexer,default_indexer,\n                        housing_indexer,loan_indexer,contact_indexer,month_indexer,poutcome_indexer,\n                        generic_assembler,rf_model])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":67},{"cell_type":"code","source":["# fitting data into the pipeline\n\nrf_fit_model=rf_pipe.fit(train_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":68},{"cell_type":"code","source":["# Store the results in a dataframe\n\nrf_results = rf_fit_model.transform(test_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":69},{"cell_type":"code","source":["rf_results.select(['y','prediction']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+\n  y|prediction|\n+---+----------+\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n+---+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":70},{"cell_type":"markdown","source":["### Gradient Boosting Classifier"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":72},{"cell_type":"code","source":["gbt_model = GBTClassifier(labelCol=\"y\", maxIter=100)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":73},{"cell_type":"code","source":["# creating pipeline for Gradinet Boosting Classifier\n\ngbt_pipe = Pipeline(stages=[job_indexer,marital_indexer,education_indexer,default_indexer,\n                        housing_indexer,loan_indexer,contact_indexer,month_indexer,poutcome_indexer,\n                        generic_assembler,gbt_model])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":74},{"cell_type":"code","source":["gbt_fit_model = gbt_pipe.fit(train_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":75},{"cell_type":"code","source":["gbt_results = gbt_fit_model.transform(test_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":76},{"cell_type":"markdown","source":["### Weighted Logistic Regression"],"metadata":{}},{"cell_type":"markdown","source":["#### In our dataset the count of positive class(customer subscribed to term deposit) is 5289 out of 45211 total instances present in the dataset and the negative class count is ~39,000 and because of this the number of 1's in the column to be predicted is very less when we pass the training dataset for model, in order to handle this imbalancing there is a technique in the Logistic Regression where we use a hyperParameter called \"weightCol\" while intializing the model, in our case we created a additional column in training dataset where we assigned the Balancing Ratio (number of negtaive instances/ total instances in dataset) to the rows which are classified to fall positive class and (1-Balancing Ratio) for the negative instances so that model would get trained better when this weighted column is introduced. \"ColumnWeights\" is the column we have created for purpose and below is the reference link that we have used\n\nhttps://medium.com/@dhiraj.p.rai/logistic-regression-in-spark-ml-8a95b5f5434c"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nindexer_job = StringIndexer(inputCol=\"job\", outputCol=\"jobIndex\")\nindexed_job_df = indexer_job.fit(df).transform(df)\nindexed_job_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+--------+\nage|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|jobIndex|\n+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+--------+\n 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown|  0|     1.0|\n 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown|  0|     2.0|\n 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown|  0|     7.0|\n 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown|  0|     0.0|\n 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown|  0|    11.0|\n 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown|  0|     1.0|\n 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown|  0|     1.0|\n 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown|  0|     7.0|\n 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown|  0|     5.0|\n 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown|  0|     2.0|\n 41|      admin.|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown|  0|     3.0|\n 29|      admin.|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown|  0|     3.0|\n 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown|  0|     2.0|\n 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown|  0|     2.0|\n 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown|  0|     4.0|\n 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown|  0|     5.0|\n 45|      admin.|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown|  0|     3.0|\n 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown|  0|     0.0|\n 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown|  0|     5.0|\n 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown|  0|     4.0|\n+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+--------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":79},{"cell_type":"code","source":["#Further expanding the same logic to other categorical columns.\n\nfrom pyspark.ml.feature import StringIndexer\nindexer_marital = StringIndexer(inputCol=\"marital\", outputCol=\"maritalIndex\")\nindexed_job_marital_df = indexer_marital.fit(indexed_job_df).transform(indexed_job_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":80},{"cell_type":"code","source":["indexer_education = StringIndexer(inputCol=\"education\", outputCol=\"educationIndex\")\nindexed_jme_df = indexer_education.fit(indexed_job_marital_df).transform(indexed_job_marital_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":81},{"cell_type":"code","source":["indexer_default = StringIndexer(inputCol=\"default\", outputCol=\"defaultIndex\")\nindexed_jmed_df = indexer_default.fit(indexed_jme_df).transform(indexed_jme_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":82},{"cell_type":"code","source":["indexer_housing = StringIndexer(inputCol=\"housing\", outputCol=\"housingIndex\")\nindexed_jmedh_df = indexer_housing.fit(indexed_jmed_df).transform(indexed_jmed_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":83},{"cell_type":"code","source":["indexer_loan = StringIndexer(inputCol=\"loan\", outputCol=\"loanIndex\")\nindexed_jmedhl_df = indexer_loan.fit(indexed_jmedh_df).transform(indexed_jmedh_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":84},{"cell_type":"code","source":["indexer_contact = StringIndexer(inputCol=\"contact\", outputCol=\"contactIndex\")\nindexed_jmedhlc_df = indexer_contact.fit(indexed_jmedhl_df).transform(indexed_jmedhl_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":85},{"cell_type":"code","source":["indexer_month = StringIndexer(inputCol=\"month\", outputCol=\"monthIndex\")\nindexed_jmedhlcm_df = indexer_month.fit(indexed_jmedhlc_df).transform(indexed_jmedhlc_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":86},{"cell_type":"code","source":["indexer_poutcome = StringIndexer(inputCol=\"poutcome\", outputCol=\"poutcomeIndex\")\nindexed_jmedhlcmp_df = indexer_poutcome.fit(indexed_jmedhlcm_df).transform(indexed_jmedhlcm_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":87},{"cell_type":"code","source":["cols = indexed_jmedhlcmp_df.columns\nfor c in {\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"poutcome\",'y'}:\n  cols.remove(c)\n\n# Let us import the vector assembler\n\nfrom pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n\n# Now let us use the transform method to transform our dataset\n\nraw_df=assembler.transform(indexed_jmedhlcmp_df)\nraw_df.select(\"features\").show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------+\nfeatures                                                               |\n+-----------------------------------------------------------------------+\n(16,[0,1,2,3,4,5,7,9,13],[58.0,2143.0,5.0,261.0,1.0,-1.0,1.0,1.0,1.0]) |\n(16,[0,1,2,3,4,5,7,8,13],[44.0,29.0,5.0,151.0,1.0,-1.0,2.0,1.0,1.0])   |\n(16,[0,1,2,3,4,5,7,12,13],[33.0,2.0,5.0,76.0,1.0,-1.0,7.0,1.0,1.0])    |\n(16,[0,1,2,3,4,5,9,13],[47.0,1506.0,5.0,92.0,1.0,-1.0,3.0,1.0])        |\n[33.0,1.0,5.0,198.0,1.0,-1.0,0.0,11.0,1.0,3.0,0.0,1.0,0.0,1.0,0.0,0.0] |\n(16,[0,1,2,3,4,5,7,9,13],[35.0,231.0,5.0,139.0,1.0,-1.0,1.0,1.0,1.0])  |\n[28.0,447.0,5.0,217.0,1.0,-1.0,0.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0]|\n[42.0,2.0,5.0,380.0,1.0,-1.0,0.0,7.0,2.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0]  |\n(16,[0,1,2,3,4,5,7,9,13],[58.0,121.0,5.0,50.0,1.0,-1.0,5.0,2.0,1.0])   |\n(16,[0,1,2,3,4,5,7,8,13],[43.0,593.0,5.0,55.0,1.0,-1.0,2.0,1.0,1.0])   |\n(16,[0,1,2,3,4,5,7,8,13],[41.0,270.0,5.0,222.0,1.0,-1.0,3.0,2.0,1.0])  |\n(16,[0,1,2,3,4,5,7,8,13],[29.0,390.0,5.0,137.0,1.0,-1.0,3.0,1.0,1.0])  |\n(16,[0,1,2,3,4,5,7,13],[53.0,6.0,5.0,517.0,1.0,-1.0,2.0,1.0])          |\n(16,[0,1,2,3,4,5,7,9,13],[58.0,71.0,5.0,71.0,1.0,-1.0,2.0,3.0,1.0])    |\n(16,[0,1,2,3,4,5,7,13],[57.0,162.0,5.0,174.0,1.0,-1.0,4.0,1.0])        |\n(16,[0,1,2,3,4,5,7,9,13],[51.0,229.0,5.0,353.0,1.0,-1.0,5.0,2.0,1.0])  |\n[45.0,13.0,5.0,98.0,1.0,-1.0,0.0,3.0,1.0,3.0,0.0,0.0,0.0,1.0,0.0,0.0]  |\n(16,[0,1,2,3,4,5,9,13],[57.0,52.0,5.0,38.0,1.0,-1.0,2.0,1.0])          |\n(16,[0,1,2,3,4,5,7,9,13],[60.0,60.0,5.0,219.0,1.0,-1.0,5.0,2.0,1.0])   |\n(16,[0,2,3,4,5,7,13],[33.0,5.0,54.0,1.0,-1.0,4.0,1.0])                 |\n+-----------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":88},{"cell_type":"code","source":["# scaling the features column\n\nfrom pyspark.ml.feature import StandardScaler\nstandardscaler = StandardScaler().setInputCol(\"features\").setOutputCol(\"features_scaled\")\nraw_df = standardscaler.fit(raw_df).transform(raw_df)\nraw_df.select(\"features\",\"features_scaled\").show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+\n            features|     features_scaled|\n+--------------------+--------------------+\n(16,[0,1,2,3,4,5,...|(16,[0,1,2,3,4,5,...|\n(16,[0,1,2,3,4,5,...|(16,[0,1,2,3,4,5,...|\n(16,[0,1,2,3,4,5,...|(16,[0,1,2,3,4,5,...|\n(16,[0,1,2,3,4,5,...|(16,[0,1,2,3,4,5,...|\n[33.0,1.0,5.0,198...|[3.10770689395434...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":89},{"cell_type":"code","source":["train_data_wl, test_data_wl = raw_df.randomSplit([0.8, 0.2])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":90},{"cell_type":"code","source":["dataset_size = df.count()\nnumNegatives = df.filter(df.y == \"false\").count()\nBalancingRatio= numNegatives/dataset_size"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":91},{"cell_type":"code","source":["train_data_wl = train_data_wl.withColumn(\"classWeights\", when(train_data_wl.y == \"true\",BalancingRatio).otherwise(1-BalancingRatio))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":92},{"cell_type":"code","source":["# Feature selection using chisquareSelector\n\nfrom pyspark.ml.feature import ChiSqSelector\ncss = ChiSqSelector(featuresCol='features_scaled',outputCol='Aspect',labelCol='y',fpr=0.05)\ntrain_data_wl=css.fit(train_data_wl).transform(train_data_wl)\ntest_data_wl=css.fit(test_data_wl).transform(test_data_wl)\ntest_data_wl.select(\"Aspect\").show(5,truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nAspect                                                                                                                                                                                                                                                |\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n[1.789285787428261,0.0183922190217475,1.4418785682684205,0.9552366318659891,0.32278672019199683,-0.009987141955157387,0.0,3.748225896840816,1.4431087955546147,2.307995517488354,0.0,2.0125672335272564,0.0,0.0,0.8016062651527387,0.0]               |\n[1.789285787428261,0.04400995265918151,3.244226778603946,1.0523135253483051,0.6455734403839937,-0.009987141955157387,0.0,3.748225896840816,1.4431087955546147,2.307995517488354,0.0,2.0125672335272564,0.0,0.0,4.008031325763693,0.0]                 |\n[1.789285787428261,0.20559873406453455,1.8023482103355255,0.4543198614972387,0.32278672019199683,-0.009987141955157387,0.0,3.748225896840816,1.4431087955546147,0.0,0.0,2.0125672335272564,0.0,3.2809168304190086,2.0040156628818466,0.0]             |\n[1.789285787428261,0.5921637660037632,2.7636005891811393,0.48150139167228717,0.32278672019199683,1.0486499052915257,0.43413309934739813,3.748225896840816,1.4431087955546147,0.0,0.0,2.0125672335272564,0.0,0.0,1.2024093977291082,1.4317020507866176]|\n(16,[0,1,2,3,4,5,8],[1.8834587236086957,0.024960868672371607,2.1628178524026307,2.481285397407996,0.6455734403839937,-0.009987141955157387,1.4431087955546147])                                                                                       |\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":93},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"y\", featuresCol=\"Aspect\",weightCol=\"classWeights\",maxIter=10)\nmodel=lr.fit(train_data_wl)\npredict_train=model.transform(train_data_wl)\npredict_test=model.transform(test_data_wl)\npredict_test.select(\"y\",\"prediction\").show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+\n  y|prediction|\n+---+----------+\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  1|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n  0|       0.0|\n+---+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":94},{"cell_type":"markdown","source":["#### Model's Evaluation"],"metadata":{}},{"cell_type":"markdown","source":["#### 1. Accuracy"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom sklearn.metrics import confusion_matrix"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":97},{"cell_type":"code","source":["#Linear SVC\nlinearsvc_acc_eval = MulticlassClassificationEvaluator(\n    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\n# Logistic Regression\nlogreg_acc_eval = MulticlassClassificationEvaluator(\n    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\n#Decision Trees\ndt_acc_eval = MulticlassClassificationEvaluator(\n    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\n#Random Forest Classifier\nrf_acc_eval = MulticlassClassificationEvaluator(\n    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\n#Gradient Boosting Classifier\ngb_acc_eval = MulticlassClassificationEvaluator(\n    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\n#Weighted Logistic Regression\nwlr_acc_eval = MulticlassClassificationEvaluator(\n    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":98},{"cell_type":"code","source":["#Linear SVC\naccuracy_linear_svc = linearsvc_acc_eval.evaluate(results_linear_svc)\n\n#Logistic Regression\nlogreg_accuracy = logreg_acc_eval.evaluate(logreg_results)\n\n#Decision Trees\ndt_accuracy = dt_acc_eval.evaluate(dt_results)\n\n#Random Forest Classifier\nrf_accuracy = rf_acc_eval.evaluate(rf_results)\n\n#Gradient Boosting Classifier\ngb_accuracy = rf_acc_eval.evaluate(gbt_results)\n\n#Weighted Logistic Regression\nwlr_accuracy = wlr_acc_eval.evaluate(predict_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":99},{"cell_type":"code","source":["#Linear SVC\nprint(\"The accuracy of linear SVC model is {}\".format(accuracy_linear_svc))\n\n#Logistic Regression\nprint(\"The accuracy of Logistic Regression model is {}\".format(logreg_accuracy))\n\n#Decision Trees\nprint(\"The accuracy of Decision Trees model is {}\".format(dt_accuracy))\n\n#Random Forest Classifier\nprint(\"The accuracy of Random Forest Classifier model is {}\".format(rf_accuracy))\n\n#Gradient Boosting Classifier\nprint(\"The accuracy of Grdaient Boosting Classifier model is {}\".format(gb_accuracy))\n\n#Weighted Logistic Regression \nprint(\"The accuracy of Weighted Logistic Regression is {}\".format(wlr_accuracy))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The accuracy of linear SVC model is 0.8808515381185912\nThe accuracy of Logistic Regression model is 0.8942264823896567\nThe accuracy of Decision Trees model is 0.8956754346856888\nThe accuracy of Random Forest Classifier model is 0.8943379402585823\nThe accuracy of Grdaient Boosting Classifier model is 0.8974587605884975\nThe accuracy of Weighted Logistic Regression is 0.8993641745231309\n</div>"]}}],"execution_count":100},{"cell_type":"markdown","source":["#### 2. Confusion Matrix"],"metadata":{}},{"cell_type":"code","source":["# Linear SVC\nfrom sklearn.metrics import confusion_matrix\ny_true = results_linear_svc.select(\"y\")\ny_true = y_true.toPandas()\ny_pred = results_linear_svc.select(\"prediction\")\ny_pred = y_pred.toPandas()\nconfusion_matrix = confusion_matrix(y_true, y_pred)\nprint(\"confusion matrix for Linear SVC Model: \\n {}\".format(confusion_matrix))\n\n# Logistic Regression\nfrom sklearn.metrics import confusion_matrix\nlogreg_y_true = logreg_results.select(\"y\")\nlogreg_y_true = logreg_y_true.toPandas()\nlogreg_y_pred = logreg_results.select(\"prediction\")\nlogreg_y_pred = logreg_y_pred.toPandas()\nlogreg_cnf_matrix = confusion_matrix(logreg_y_true, logreg_y_pred)\nprint(\"confusion matrix for Logistic Regression Model \\n {}\".format(logreg_cnf_matrix))\n\n#Decision Trees\nfrom sklearn.metrics import confusion_matrix\ndt_y_true = dt_results.select(\"y\")\ndt_y_true = dt_y_true.toPandas()\ndt_y_pred = dt_results.select(\"prediction\")\ndt_y_pred = dt_y_pred.toPandas()\ndt_cnf_matrix = confusion_matrix(dt_y_true, dt_y_pred)\nprint(\"confusion matrix for Decision Trees Model\\n {}\".format(dt_cnf_matrix))\n\n#Random Forest Classifier\nfrom sklearn.metrics import confusion_matrix\nrf_y_true = rf_results.select(\"y\")\nrf_y_true = rf_y_true.toPandas()\nrf_y_pred = rf_results.select(\"prediction\")\nrf_y_pred = rf_y_pred.toPandas()\nrf_cnf_matrix = confusion_matrix(rf_y_true, rf_y_pred)\nprint(\"confusion matrix for Random Forest Classifier \\n {}\".format(rf_cnf_matrix))\n\n#Gradient Boosting Classifier\nfrom sklearn.metrics import confusion_matrix\ngb_y_true = gbt_results.select(\"y\")\ngb_y_true = gb_y_true.toPandas()\ngb_y_pred = gbt_results.select(\"prediction\")\ngb_y_pred = gb_y_pred.toPandas()\ngb_cnf_matrix = confusion_matrix(gb_y_true, gb_y_pred)\nprint(\"confusion matrix for Gradient Boosting Classifier \\n {}\".format(gb_cnf_matrix))\n\n#Weighted Logistic Regression Model\nfrom sklearn.metrics import confusion_matrix\nwlr_y_true = predict_test.select(\"y\")\nwlr_y_true = wlr_y_true.toPandas()\nwlr_y_pred = predict_test.select(\"prediction\")\nwlr_y_pred = wlr_y_pred.toPandas()\nwlr_cnf_matrix = confusion_matrix(wlr_y_true, wlr_y_pred)\nprint(\"confusion matrix for Weighted Logistic Regression Model \\n {}\".format(wlr_cnf_matrix))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">confusion matrix for Linear SVC Model: \n [[7903    0]\n [1069    0]]\nconfusion matrix for Logistic Regression Model \n [[7816   87]\n [ 862  207]]\nconfusion matrix for Decision Trees Model\n [[7855   48]\n [ 888  181]]\nconfusion matrix for Random Forest Classifier \n [[7863   40]\n [ 908  161]]\nconfusion matrix for Gradient Boosting Classifier \n [[7774  129]\n [ 791  278]]\nconfusion matrix for Weighted Logistic Regression Model \n [[7864  171]\n [ 747  340]]\n</div>"]}}],"execution_count":102},{"cell_type":"markdown","source":["### Precision and Recall"],"metadata":{}},{"cell_type":"code","source":["#Linear SVC\nfrom sklearn.metrics import precision_score,recall_score\nlsvc_precision_score = precision_score(y_true,y_pred)\nlsvc_recall_score = recall_score(y_true,y_pred)\nprint(\"Precision Score for Linear SVC Model: \\n {}\".format(lsvc_precision_score))\nprint(\"Recall Score for Linear SVC Model: \\n {}\".format(lsvc_recall_score))\n\n#Logistic Regression Model\nfrom sklearn.metrics import precision_score,recall_score\nlogreg_precision_score = precision_score(logreg_y_true,logreg_y_pred)\nlogreg_recall_score = recall_score(logreg_y_true,logreg_y_pred)\nprint(\"Precision Score for Logistic Regression Model: \\n {}\".format(logreg_precision_score))\nprint(\"Recall Score for Logistic Regression Model: \\n {}\".format(logreg_recall_score))\n\n#Decision Trees\nfrom sklearn.metrics import precision_score,recall_score\ndt_precision_score = precision_score(dt_y_true,dt_y_pred)\ndt_recall_score = recall_score(dt_y_true,dt_y_pred)\nprint(\"Precision Score for Decision Trees Model: \\n {}\".format(dt_precision_score))\nprint(\"Recall Score for Decision Trees Model: \\n {}\".format(dt_recall_score))\n\n#Random Forest Classifier\nfrom sklearn.metrics import precision_score,recall_score\nrf_precision_score = precision_score(rf_y_true,rf_y_pred)\nrf_recall_score = recall_score(rf_y_true,rf_y_pred)\nprint(\"Precision Score for Random Forest Classifier Model: \\n {}\".format(rf_precision_score))\nprint(\"Recall Score for Random Forest Classifier Model: \\n {}\".format(rf_recall_score))\n\n#Gradient Boosting Classifier\nfrom sklearn.metrics import precision_score,recall_score\ngb_precision_score = precision_score(gb_y_true,gb_y_pred)\ngb_recall_score = recall_score(gb_y_true,gb_y_pred)\nprint(\"Precision Score for Gradient Boosting Classifier Model: \\n {}\".format(gb_precision_score))\nprint(\"Recall Score for Gradient Boosting Classifier Model: \\n {}\".format(gb_recall_score))\n\n#Weighted Logistic Regression Model\nfrom sklearn.metrics import precision_score,recall_score\nwlg_precision_score = precision_score(wlr_y_true,wlr_y_pred)\nwlg_recall_score = recall_score(wlr_y_true,wlr_y_pred)\nprint(\"Precision Score for Weighted Logistic Regression Model Model: \\n {}\".format(wlg_precision_score))\nprint(\"Recall Score for Weighted Logistic Regression Model Model: \\n {}\".format(wlg_recall_score))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Precision Score for Linear SVC Model: \n 0.0\nRecall Score for Linear SVC Model: \n 0.0\nPrecision Score for Logistic Regression Model: \n 0.7040816326530612\nRecall Score for Logistic Regression Model: \n 0.19363891487371376\nPrecision Score for Decision Trees Model: \n 0.7903930131004366\nRecall Score for Decision Trees Model: \n 0.16931711880261927\nPrecision Score for Random Forest Classifier Model: \n 0.8009950248756219\nRecall Score for Random Forest Classifier Model: \n 0.15060804490177737\nPrecision Score for Gradient Boosting Classifier Model: \n 0.683046683046683\nRecall Score for Gradient Boosting Classifier Model: \n 0.2600561272217025\nPrecision Score for Weighted Logistic Regression Model Model: \n 0.6653620352250489\nRecall Score for Weighted Logistic Regression Model Model: \n 0.31278748850046\n</div>"]}}],"execution_count":104},{"cell_type":"markdown","source":["### Results"],"metadata":{}},{"cell_type":"markdown","source":["#### For the business case that we have taken, the predictive models that we have developed will have an impact when they are able to predict correctly whether customer would be subscribing for the term deposit offered by the bank, so in our case the focus should be on approaching/reaching out to the customers who are willing to subscribe, in this scenario the most important aspect that we should look at is how many times the model is correctly predicting that customer would subscribe when they are subscribing in reality, that is in actual positive class (where customer is subscribing) the number of times where model is predicting that customer would subscribe (predicted positive class) should be high, this ensures that we are not ignoring that particular customers who are actually willing to subscribe to term deposit, becuase this would be beneficial to the company and is the core aspect of our classification task here. \n\n\n1.Linear SVC Model has predicted that 0 customers are subscribing to term deposits when actually 1069 customers are subscribing, though this model has 88% accuracy this does not provide any value to the company by using this model since this model has predicted no customer subscribed, in our business case/scenario accuracy does not have a greater significance rather we should concentrate more on recall followed by precision metrics.\n\n\n2.Logistic Regression Model has predicted that out of 1069 actual subscriptions for the term deposit, it predicted 207 times correctly and out of 7093 cases where customers did not subscribe for term deposits in real it predicted 7816 times correctly.\n\n3.Decision Tree Classifier has predicted that out of 1069 actual subscriptions for the term deposit, it predicted 181 times correctly and out of 7093 cases where customers did not subscribe for term deposits in real it predicted 7855 times correctly.\n\n4.Random Forest Classifier has predicted that out of 1069 actual subscriptions for the term deposit, it predicted 161 times correctly and out of 7093 cases where customers did not subscribe for term deposits in real it predicted 7863 times correctly.\n\n5.Gradient Boosting Classifier has predicted that out of 1069 actual subscriptions for the term deposit, it predicted 278 times correctly and out of 7093 cases where customers did not subscribe for term deposits in real it predicted 7774 times correctly.\n\n\n6.Weighted Logistic Regression has predicted that out of 1069 actual subscriptions for the term deposit, it predicted 340 times correctly and out of 7093 cases where customers did not subscribe for term deposits in real it predicted 7864 times correctly.\n\nBased on the above explanation and by looking at the above True Positive Count and Flase Negative count from the confusion matrix of different models Weighted Logistic Expression is the best model compared to remaining models since it has the maximum count for an \"Actual Yes\" and \"Predicted Yes\" Scenario which is of the prime importance to us and low value for \"Actual Yes\" and Predicted \"No Scenario\"\n\nBased on the above explanation when we calculate the precision and recall score for each model using the respective confusion matrices and considering there needs to be a trade between the precision and recall we can say that Weighted Logistic Regression (precision 66.5% and recall 32 %) is the best model we have got to use on this dataset whether a customer would be subscribing to term deposit or not"],"metadata":{}},{"cell_type":"markdown","source":["### Area under ROC and PR Curves"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nAUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='y',metricName='areaUnderROC')\nPR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='y',metricName='areaUnderPR')\n\n#Linear SVC\nAUC = AUC_evaluator.evaluate(results_linear_svc)\nprint(\"Area under the ROC curve for Linear SVC Model is {}\".format(AUC))\nPR = PR_evaluator.evaluate(results_linear_svc)\nprint(\"Area under the PR curve for Linear SVC Model is {}\\n\".format(PR))\n\n#Logistic Regression\nAUC = AUC_evaluator.evaluate(logreg_results)\nprint(\"Area under the ROC curve for Logistic Regression Model is {}\".format(AUC))\nPR = PR_evaluator.evaluate(logreg_results)\nprint(\"Area under the PR curve for Logistic Regression Model is {}\\n\".format(PR))\n\n#Decision Trees\nAUC = AUC_evaluator.evaluate(dt_results)\nprint(\"Area under the ROC curve for Decision Trees is {}\".format(AUC))\nPR = PR_evaluator.evaluate(dt_results)\nprint(\"Area under the PR curve for Decision Trees is {}\\n\".format(PR))\n\n#Random Forests\nAUC = AUC_evaluator.evaluate(rf_results)\nprint(\"Area under the ROC curve for Random Forests is {}\".format(AUC))\nPR = PR_evaluator.evaluate(rf_results)\nprint(\"Area under the PR curve for Random Forests is {}\\n\".format(PR))\n\n#Gradient Boosting Classifier\nAUC = AUC_evaluator.evaluate(gbt_results)\nprint(\"Area under the ROC curve for Gradient Boosting Classifier is {}\".format(AUC))\nPR = PR_evaluator.evaluate(gbt_results)\nprint(\"Area under the PR curve for Gradient Boosting Classifier is {}\\n\".format(PR))\n\n#Weighted Logistic Regression\nAUC = AUC_evaluator.evaluate(predict_test)\nprint(\"Area under the ROC curve for Weighted Logistic Regression Model is {}\".format(AUC))\nPR = PR_evaluator.evaluate(predict_test)\nprint(\"Area under the PR curve for Weighted Logistic Regression Model is {}\\n\".format(PR))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under the ROC curve for Linear SVC Model is 0.5\nArea under the PR curve for Linear SVC Model is 0.11914846188140883\n\nArea under the ROC curve for Logistic Regression Model is 0.5913152185402353\nArea under the PR curve for Logistic Regression Model is 0.4682479594981668\n\nArea under the ROC curve for Decision Trees is 0.5816217379411046\nArea under the PR curve for Decision Trees is 0.5115973342031042\n\nArea under the ROC curve for Random Forests is 0.5727733379007179\nArea under the PR curve for Random Forests is 0.5114175322662928\n\nArea under the ROC curve for Gradient Boosting Classifier is 0.6218666059365504\nArea under the PR curve for Gradient Boosting Classifier is 0.47442016623577005\n\nArea under the ROC curve for Weighted Logistic Regression Model is 0.6457527983883756\nArea under the PR curve for Weighted Logistic Regression Model is 0.47768444579204944\n\n</div>"]}}],"execution_count":108},{"cell_type":"markdown","source":["### ROC Curve Plots"],"metadata":{}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\nimport matplotlib\nimport matplotlib.pyplot as plt\n\ny_true_array = [y_true, logreg_y_true, dt_y_true, rf_y_true, gb_y_true, wlr_y_true]\ny_pred_array = [y_pred, logreg_y_pred, dt_y_pred, rf_y_pred, gb_y_pred, wlr_y_pred]\n\nfor i in range(len(y_true_array)):\n  fpr, tpr, thresholds = roc_curve(y_true_array[i], y_pred_array[i] ,pos_label=1)\n  plt.plot(fpr, tpr)\n  plt.plot([0, 1], [0, 1], 'k--')\n  plt.axis([0, 1, 0, 1])\n  if i==0:\n    plt.xlabel('ROC Curve of Linear SVC Model')\n  elif i==1:\n    plt.xlabel(\"ROC Curve of Logistic Regression Model\")\n  elif i == 2:\n    plt.xlabel(\"ROC Curve of Decision Trees Classifier\")\n  elif i == 3:\n    plt.xlabel(\"ROC Curve of Random Forest Classifier\")\n  elif i == 4:\n    plt.xlabel(\"ROC Curve of Gradient Boosting Classifier\")\n  elif i == 5:\n    plt.xlabel(\"ROC Curve of Weighted Logistic Regression Model\")\n  display(plt.show())"],"metadata":{},"outputs":[],"execution_count":110}],"metadata":{"name":"Project - SubscribeTermDeposit","notebookId":1432922821597385},"nbformat":4,"nbformat_minor":0}
